{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time-Weighted Annual CNB Repo Rates\n",
    "\n",
    "**Data Source**  \n",
    "A text file listing CNB repo rate decisions. Each decision is valid until the next one begins.\n",
    "\n",
    "**Method**  \n",
    "- **Time Weighting**: Instead of taking a simple average of all rates in a given year, we break each `[start_date, next_start)` interval by calendar year boundaries and compute a time‚Äêweighted average. This ensures that a rate valid for a longer period has a proportionally bigger impact on the annual average.\n",
    "\n",
    "**Justification**  \n",
    "- **Accuracy**: Merely averaging rate values ignores how long each rate was in effect. Time weighting aligns the annual rate with real monetary policy conditions experienced throughout the year.\n",
    "- **Usability**: The resulting annual series can be easily merged with other macro data (HICP, wages, etc.) for subsequent econometric analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "script_dir = os.getcwd()  # Jupyter Notebook working directory\n",
    "project_root = os.path.abspath(os.path.join(script_dir, \"..\"))\n",
    "input_file = os.path.join(project_root, \"data\", \"source_raw\", \"economy\", \"CNB_repo_sazby.txt\")\n",
    "output_folder = os.path.join(project_root, \"data\", \"source_cleaned\")\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "output_file = os.path.join(output_folder, \"cnb_repo_annual.parquet\")\n",
    "\n",
    "# Read data\n",
    "df_repo = pd.read_csv(\n",
    "    input_file,\n",
    "    sep=\"|\",\n",
    "    names=[\"VALID_FROM\", \"CNB_REPO_RATE_IN_PCT\"],\n",
    "    header=None,\n",
    "    dtype={\"VALID_FROM\": str}\n",
    ")\n",
    "df_repo[\"VALID_FROM\"] = pd.to_datetime(df_repo[\"VALID_FROM\"], format=\"%Y%m%d\", errors=\"coerce\")\n",
    "df_repo[\"CNB_REPO_RATE_IN_PCT\"] = pd.to_numeric(df_repo[\"CNB_REPO_RATE_IN_PCT\"], errors=\"coerce\")\n",
    "df_repo.dropna(subset=[\"VALID_FROM\"], inplace=True)\n",
    "\n",
    "df_repo.sort_values(\"VALID_FROM\", inplace=True)\n",
    "\n",
    "# Next start date (rates are valid until the day before the next decision)\n",
    "df_repo[\"NEXT_START\"] = df_repo[\"VALID_FROM\"].shift(-1)\n",
    "\n",
    "# Define cutoff for the last row\n",
    "if not df_repo.empty:\n",
    "    last_idx = df_repo.index[-1]\n",
    "    last_year = df_repo.loc[last_idx, \"VALID_FROM\"].year\n",
    "    cutoff_date = pd.to_datetime(f\"{last_year + 1}-12-31\")\n",
    "    df_repo.loc[last_idx, \"NEXT_START\"] = cutoff_date\n",
    "\n",
    "def split_interval_by_year(start_date, end_date):\n",
    "    \"\"\"Break [start_date, end_date) into sub-intervals by calendar year.\"\"\"\n",
    "    end_date = end_date - pd.Timedelta(days=1)\n",
    "    if end_date < start_date:\n",
    "        return []\n",
    "    intervals, current = [], start_date\n",
    "    while current <= end_date:\n",
    "        year_end = pd.to_datetime(f\"{current.year}-12-31\")\n",
    "        local_end = min(year_end, end_date)\n",
    "        delta = (local_end - current).days + 1\n",
    "        intervals.append({\"year\": current.year, \"days_in_interval\": delta})\n",
    "        current = local_end + pd.Timedelta(days=1)\n",
    "    total_days = (end_date - start_date).days + 1\n",
    "    for iv in intervals:\n",
    "        iv[\"total_days_for_rate\"] = total_days\n",
    "    return intervals\n",
    "\n",
    "records = []\n",
    "for _, row in df_repo.iterrows():\n",
    "    intervals = split_interval_by_year(row[\"VALID_FROM\"], row[\"NEXT_START\"])\n",
    "    rate = row[\"CNB_REPO_RATE_IN_PCT\"]\n",
    "    for iv in intervals:\n",
    "        frac = iv[\"days_in_interval\"] / iv[\"total_days_for_rate\"]\n",
    "        records.append({\n",
    "            \"year\": iv[\"year\"],\n",
    "            \"repo_rate\": rate,\n",
    "            \"weighted_rate\": rate * frac\n",
    "        })\n",
    "\n",
    "df_intervals = pd.DataFrame(records)\n",
    "if not df_intervals.empty:\n",
    "    # Sum up weighted rates per year\n",
    "    annual_data = df_intervals.groupby(\"year\", as_index=False).agg(\n",
    "        sum_weighted=(\"weighted_rate\", \"sum\"),\n",
    "        sum_rates=(\"repo_rate\", \"count\")  # Not strictly needed, but can track intervals\n",
    "    )\n",
    "    # The sum of weighted_rate for each year is our time-weighted value,\n",
    "    # because each interval's fraction sums to 1 if the year is fully covered.\n",
    "    # However, to confirm partial coverage, let's also track fraction_of_interval:\n",
    "    # (We'll just treat the sum of weighted_rate as the annual average directly.)\n",
    "    \n",
    "    # Alternatively, we can track fraction_of_interval if needed:\n",
    "    # df_intervals[\"fraction_of_interval\"] = df_intervals[\"weighted_rate\"] / df_intervals[\"repo_rate\"]\n",
    "    # Then group and do the final average. For simplicity, let's proceed with the sum of weighted_rate:\n",
    "    \n",
    "    # Weighted average = sum(weighted_rate)\n",
    "    # => We must ensure each year was fully covered for that to reflect a 100% fraction.\n",
    "    # If partial coverage, the sum will be < the actual expected value.\n",
    "    # For a robust approach, let's recalculate fraction_of_interval in the table:\n",
    "    df_intervals[\"fraction_of_interval\"] = df_intervals[\"weighted_rate\"] / df_intervals[\"repo_rate\"]\n",
    "    annual_fracs = df_intervals.groupby(\"year\")[\"fraction_of_interval\"].sum().reset_index()\n",
    "    annual_merged = annual_data.merge(annual_fracs, on=\"year\", how=\"left\")\n",
    "    annual_merged.rename(columns={\"fraction_of_interval\": \"sum_fraction\"}, inplace=True)\n",
    "    \n",
    "    # Final annual rate = sum of weighted_rate / sum_fraction\n",
    "    # sum_weighted is the sum of (rate * fraction_i)\n",
    "    annual_merged[\"cnb_repo_rate_annual\"] = (\n",
    "        annual_merged[\"sum_weighted\"] / annual_merged[\"sum_fraction\"]\n",
    "    )\n",
    "    \n",
    "    final_annual = annual_merged[[\"year\", \"cnb_repo_rate_annual\"]].sort_values(\"year\")\n",
    "    # drop years pre 2000 and post 2024\n",
    "    final_annual = final_annual[final_annual[\"year\"] >= 2000]\n",
    "    final_annual = final_annual[final_annual[\"year\"] <= 2024]\n",
    "    # Save to parquet\n",
    "    #final_annual.to_parquet(output_file, engine=\"pyarrow\", compression=\"snappy\", index=False)\n",
    "    #print(f\"Time-weighted annual CNB repo rates saved to: {output_file}\")\n",
    "    #display(final_annual.head(25))\n",
    "else:\n",
    "    print(\"No records found after year 2000.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annual HICP Data Preparation\n",
    "\n",
    "**Data Source:**  \n",
    "Monthly HICP data (Overall index) with columns:\n",
    "- `DATE` (e.g., \"1996-12-31\")\n",
    "- `TIME PERIOD`\n",
    "- `\"HICP - Overall index (ICP.M.CZ.N.000000.4.ANR)\"`\n",
    "\n",
    "**Method:**  \n",
    "- **Parse Dates & Numeric Conversion:**  \n",
    "  Convert the `DATE` column to datetime and the HICP index column to numeric.\n",
    "- **Filter December Values:**  \n",
    "  Select only records where the month is December. December data represents the end-of-year value, which is often used as the annual measure.\n",
    "- **Extract Year:**  \n",
    "  Create a `year` column from the December dates.\n",
    "- **Output:**  \n",
    "  The resulting DataFrame contains one observation per year with columns `year` and `hicp_dec`. This annual series will serve as the base for merging with other macroeconomic data.\n",
    "\n",
    "**Justification:**  \n",
    "Using December values provides a consistent, end-of-year snapshot. This harmonized annual format simplifies integration with datasets such as the CNB repo rates and firm-level financial data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annual HICP (December values) saved to: /Users/adam/Library/Mobile Documents/com~apple~CloudDocs/School/Master's Thesis/Analysis/profit-margins-inflation/data/source_cleaned/hicp_december_annual.parquet\n"
     ]
    }
   ],
   "source": [
    "# Define file paths\n",
    "script_dir = os.getcwd()  # Current directory in Jupyter\n",
    "project_root = os.path.abspath(os.path.join(script_dir, \"..\"))\n",
    "input_file = os.path.join(project_root, \"data\", \"source_raw\", \"economy\", \"ECB Data Portal_20250402011223_HICP_from1996_CZ.csv\")\n",
    "output_folder = os.path.join(project_root, \"data\", \"source_cleaned\")\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "output_file = os.path.join(output_folder, \"hicp_december_annual.parquet\")\n",
    "\n",
    "# Read the HICP data\n",
    "df_hicp = pd.read_csv(input_file)\n",
    "\n",
    "# Convert DATE column to datetime\n",
    "df_hicp[\"DATE\"] = pd.to_datetime(df_hicp[\"DATE\"], format=\"%Y-%m-%d\", errors=\"coerce\")\n",
    "\n",
    "# Convert HICP index column to numeric\n",
    "df_hicp[\"hicp_dec\"] = pd.to_numeric(df_hicp[\"HICP - Overall index (ICP.M.CZ.N.000000.4.ANR)\"], errors=\"coerce\")\n",
    "\n",
    "# Filter to keep only December observations\n",
    "df_hicp_dec = df_hicp[df_hicp[\"DATE\"].dt.month == 12].copy()\n",
    "\n",
    "# Extract year from DATE\n",
    "df_hicp_dec[\"year\"] = df_hicp_dec[\"DATE\"].dt.year\n",
    "\n",
    "# Select only the required columns for annual data\n",
    "df_hicp_annual = df_hicp_dec[[\"year\", \"hicp_dec\"]].reset_index(drop=True)\n",
    "\n",
    "# remove pre 2000 data\n",
    "df_hicp_annual = df_hicp_annual[df_hicp_annual[\"year\"] >= 2000]\n",
    "\n",
    "# Save the annual HICP data to a Parquet file\n",
    "df_hicp_annual.to_parquet(output_file, engine=\"pyarrow\", compression=\"snappy\", index=False)\n",
    "\n",
    "print(\"Annual HICP (December values) saved to:\", output_file)\n",
    "#display(df_hicp_annual.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annual Wages & Employees Data Preparation\n",
    "\n",
    "**Data Source:**  \n",
    "Excel file (`pmzcr030625_1_wages_avg.xlsx`) - CZSO reporting average gross monthly wages and average employee counts (in thousands) per full-time equivalent.\n",
    "\n",
    "**Process:**\n",
    "- **Select & Rename:**  \n",
    "  Extract the year, nominal wage (CZK), and number of employees columns; rename them to `year`, `nom_gr_avg_wage_czk`, and `no_of_employees_ths`.\n",
    "- **Filter Rows:**  \n",
    "  Retain only the first 25 rows (annual values).\n",
    "- **Clean Data:**  \n",
    "  Correct irregular year entries (e.g., \"20233)\" ‚Üí \"2023\"), convert `year` to integer, and ensure wage and employee columns are numeric.\n",
    "  - values for 2023 and 2024 are preliminary\n",
    "- **Output:**  \n",
    "  Save the cleaned annual data as a Parquet.\n",
    "\n",
    "**Rationale:**  \n",
    "Focusing on annual data and standardizing types streamlines merging with other macro series (e.g., CNB repo rates, HICP) and minimizes processing errors.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths\n",
    "script_dir = os.getcwd()  # Current directory in Jupyter\n",
    "project_root = os.path.abspath(os.path.join(script_dir, \"..\"))\n",
    "input_file = os.path.join(project_root, \"data\", \"source_raw\", \"economy\", \"pmzcr030625_1_wages_avg.xlsx\")\n",
    "output_folder = os.path.join(project_root, \"data\", \"source_cleaned\")\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "output_file = os.path.join(output_folder, \"wages_no_employees_annual.parquet\")\n",
    "\n",
    "# Read the Excel file\n",
    "df_wages = pd.read_excel(input_file, sheet_name=\"List1\", skiprows=4)\n",
    "\n",
    "# select only the relevant columns: 0 (year), 1 - nominal wage CZK, 4 - no of employees in thousands\n",
    "# and rename them\n",
    "df_wages = df_wages.iloc[:, [0, 1, 4]].rename(columns={\n",
    "    df_wages.columns[0]: \"year\",\n",
    "    df_wages.columns[1]: \"nom_gr_avg_wage_czk\",\n",
    "    df_wages.columns[4]: \"no_of_employees_ths\"\n",
    "}) \n",
    "\n",
    "# select only first 25 rows (yearly values)\n",
    "df_wages = df_wages.iloc[1:26].copy()\n",
    "# Convert the year column to int\n",
    "#df_wages[\"year\"] = df_wages[\"year\"].astype(int, errors=\"coerce\")\n",
    "\n",
    "# replace 20233) and 20243) by 2023 and 2024 in year col (this was a reference)\n",
    "df_wages[\"year\"] = df_wages[\"year\"].replace({\"20233)\": \"2023\", \"20243)\": \"2024\"})\n",
    "\n",
    "# Convert the year column to int\n",
    "df_wages[\"year\"] = df_wages[\"year\"].astype(int, errors=\"ignore\")\n",
    "# Convert the nominal wage column to numeric\n",
    "df_wages[\"nom_gr_avg_wage_czk\"] = pd.to_numeric(df_wages[\"nom_gr_avg_wage_czk\"], errors=\"coerce\")\n",
    "# # Convert the number of employees column to numeric\n",
    "df_wages[\"no_of_employees_ths\"] = pd.to_numeric(df_wages[\"no_of_employees_ths\"], errors=\"coerce\")\n",
    "\n",
    "# save to parquet\n",
    "#df_wages.to_parquet(output_file, engine=\"pyarrow\", compression=\"snappy\", index=False)\n",
    "#print(\"Annual wages data and no. of employees saved to:\", output_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GDP Data Preparation\n",
    "\n",
    "**Data Source:** CZSO\n",
    "\n",
    "Hruby domaci produkt - stale ceny z r 2020\n",
    "\n",
    "K√≥d: NUCDUSHV01-R/11\n",
    "V√Ωpoƒçet ukazatel≈Ø ve st√°l√Ωch cen√°ch roku 2020 byl proveden metodou ≈ôetƒõzen√≠ meziroƒçn√≠ch index≈Ø (vypoƒçten√Ωch v≈ædy na b√°zi pr≈Ømƒõru p≈ôedchoz√≠ho roku). Tato metoda zaji≈°≈•uje vazbu ukazatel≈Ø ve ƒçtvrtletn√≠ a roƒçn√≠ periodicitƒõ, ale neumo≈æ≈àuje vazbu jednotliv√Ωch komponent na √∫hrn.\n",
    "SOPR ‚Äì stejn√© obdob√≠ p≈ôedchoz√≠ho roku.\n",
    "odhad podle sumy kvart. hodnot\n",
    "\n",
    " **\"St√°l√© ceny roku 2020\"** column. This column represents GDP in constant prices (with 2020 as the base year), allowing you to compare real economic growth over time without the distortions caused by price changes.\n",
    "\n",
    "**Why \"St√°l√© ceny roku 2020\" is preferable:**\n",
    "\n",
    "- **Removes Inflation Effects:**  \n",
    "measure the true volume of economic activity rather than nominal changes that include inflation.\n",
    "\n",
    "- **Consistent Time Comparison:**  \n",
    "  It enables a more accurate comparison of economic performance across different years, as all values are adjusted to the price level of the base year (2020).\n",
    "\n",
    "- **Policy Analysis Relevance:**  \n",
    "  For studies that examine relationships between variables like profit margins and inflation, it‚Äôs crucial to work with real output measures. This helps in isolating the effect of inflation from other factors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adam/opt/anaconda3/envs/thesis_env/lib/python3.13/site-packages/openpyxl/styles/stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    }
   ],
   "source": [
    "# Define file paths\n",
    "script_dir = os.getcwd()  # Current directory in Jupyter\n",
    "project_root = os.path.abspath(os.path.join(script_dir, \"..\"))\n",
    "input_file = os.path.join(project_root, \"data\", \"source_raw\", \"economy\", \"NUCDUSHV01-R_CZSO_GDP.xlsx\")\n",
    "output_folder = os.path.join(project_root, \"data\", \"source_cleaned\")\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "output_file = os.path.join(output_folder, \"gdp_annual.parquet\")\n",
    "\n",
    "# Read the Excel file\n",
    "df_gdp = pd.read_excel(input_file, sheet_name=\"DATA\", skiprows=6)\n",
    "\n",
    "# Select only the relevant columns: 1 (year), 2 - GDP nominal prices, 4 - GDP 2020 base prices, 5 - GDP 2020 base prices SOPR (stejn√© obdob√≠ p≈ôedchoz√≠ho roku), 6 - deflator nominal, 7 - deflator base 2020\n",
    "# and rename them\n",
    "df_gdp = df_gdp.iloc[:, [1, 2, 4, 5, 6, 7]].rename(columns={\n",
    "    df_gdp.columns[1]: \"year\",\n",
    "    df_gdp.columns[2]: \"gdp_nominal_prices\",\n",
    "    df_gdp.columns[4]: \"gdp_2020_base_prices\",\n",
    "    df_gdp.columns[5]: \"gdp_2020_base_prices_sopr\",\n",
    "    df_gdp.columns[6]: \"deflator_nominal\",\n",
    "    df_gdp.columns[7]: \"deflator_base_2020\"\n",
    "})\n",
    "\n",
    "# Select only first 24 rows (yearly values)\n",
    "df_gdp = df_gdp.iloc[0:25].copy()\n",
    "\n",
    "# adjust \"2024 [3]\" - keep first 4 characters only \n",
    "df_gdp[\"year\"] = df_gdp[\"year\"].str[:4]\n",
    "\n",
    "# Convert the year column to int\n",
    "df_gdp[\"year\"] = df_gdp[\"year\"].astype(int, errors=\"ignore\")\n",
    "\n",
    "# Convert the GDP columns to numeric\n",
    "df_gdp[\"gdp_nominal_prices\"] = pd.to_numeric(df_gdp[\"gdp_nominal_prices\"], errors=\"coerce\")\n",
    "df_gdp[\"gdp_2020_base_prices\"] = pd.to_numeric(df_gdp[\"gdp_2020_base_prices\"], errors=\"coerce\")\n",
    "df_gdp[\"gdp_2020_base_prices_sopr\"] = pd.to_numeric(df_gdp[\"gdp_2020_base_prices_sopr\"], errors=\"coerce\")\n",
    "df_gdp[\"deflator_nominal\"] = pd.to_numeric(df_gdp[\"deflator_nominal\"], errors=\"coerce\")\n",
    "df_gdp[\"deflator_base_2020\"] = pd.to_numeric(df_gdp[\"deflator_base_2020\"], errors=\"coerce\")\n",
    "\n",
    "# Save to parquet\n",
    "\n",
    "#df_gdp.to_parquet(output_file, engine=\"pyarrow\", compression=\"snappy\", index=False)\n",
    "#print(\"Annual GDP data saved to:\", output_file)\n",
    "#display(df_gdp.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unemployment rate Data Preparation\n",
    "\n",
    "source: CZSO \n",
    "Obecn√° m√≠ra nezamƒõstnanosti - Ceska republika\n",
    "\n",
    "chosen based on data availability from 2000\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adam/opt/anaconda3/envs/thesis_env/lib/python3.13/site-packages/openpyxl/styles/stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    }
   ],
   "source": [
    "# Define file paths\n",
    "script_dir = os.getcwd()  # Current directory in Jupyter\n",
    "project_root = os.path.abspath(os.path.join(script_dir, \"..\"))\n",
    "input_file = os.path.join(project_root, \"data\", \"source_raw\", \"economy\", \"ZAMDPORK02_unemployment.xlsx\")\n",
    "output_folder = os.path.join(project_root, \"data\", \"source_cleaned\")\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "output_file = os.path.join(output_folder, \"unemp_rate_annual.parquet\")\n",
    "\n",
    "# Read the Excel file\n",
    "df_unemp = pd.read_excel(input_file, sheet_name=\"DATA\", skiprows=6)\n",
    "\n",
    "# drop first column \n",
    "df_unemp.drop(df_unemp.columns[0], axis=1, inplace=True)\n",
    "\n",
    "# drop all rows except the first \n",
    "df_unemp = df_unemp.iloc[0:1].copy()\n",
    "\n",
    "# the data is in wide format, so we need to transpose it\n",
    "df_unemp = df_unemp.transpose()\n",
    "\n",
    "# drop Czech republic row 1st\n",
    "df_unemp.drop(df_unemp.index[0], inplace=True)\n",
    "\n",
    "# rename columns: from index to year\n",
    "df_unemp.reset_index(inplace=True)\n",
    "df_unemp.rename(columns={\"index\": \"year\"}, inplace=True)\n",
    "# Convert the year column to int\n",
    "df_unemp[\"year\"] = df_unemp[\"year\"].astype(int, errors=\"ignore\")\n",
    "\n",
    "# rename column: 0 to unemp_rate\n",
    "df_unemp.rename(columns={df_unemp.columns[1]: \"unemp_rate\"}, inplace=True)\n",
    "\n",
    "# Convert the unemployment rate column to numeric\n",
    "df_unemp[\"unemp_rate\"] = pd.to_numeric(df_unemp[\"unemp_rate\"], errors=\"coerce\")\n",
    "\n",
    "# save to parquet\n",
    "# df_unemp.to_parquet(output_file, engine=\"pyarrow\", compression=\"snappy\", index=False)\n",
    "# print(\"Annual unemployment rate data saved to:\", output_file)\n",
    "#display(df_unemp.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FX rates \n",
    "\n",
    "source: CNB (https://www.cnb.cz/en/financial-markets/foreign-exchange-market/central-bank-exchange-rate-fixing/central-bank-exchange-rate-fixing/currency_average.html?currency=EUR)\n",
    "\n",
    "- **Data Source:** CNB\n",
    "- **Data Type:** Average Qty FX rates\n",
    "\n",
    "- **Data Format:** txt\n",
    "\n",
    "we calculate an annual FX rate by taking the simple average of the four quarterly values, since each quarter is weighted equally (3 months). This arithmetic average provides a reasonable approximation of the yearly exchange rate.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths\n",
    "script_dir = os.getcwd()  # Current directory in Jupyter\n",
    "project_root = os.path.abspath(os.path.join(script_dir, \"..\"))\n",
    "input_file = os.path.join(project_root, \"data\", \"source_raw\", \"economy\", \"CNB FX rates from 1999.txt\")\n",
    "output_folder = os.path.join(project_root, \"data\", \"source_cleaned\")\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "output_file = os.path.join(output_folder, \"fx_rates_annual.parquet\")\n",
    "\n",
    "# Read the FX rates data\n",
    "df_fx = pd.read_csv(\n",
    "    input_file,\n",
    "    sep=\"|\",\n",
    ")\n",
    "\n",
    "# convert year to integer\n",
    "df_fx[\"year\"] = df_fx[\"year\"].astype(int, errors=\"ignore\")\n",
    "\n",
    "# convert all columns to numeric\n",
    "df_fx.iloc[:, 1:] = df_fx.iloc[:, 1:].apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "# calculate mean for each row \n",
    "# and add it to the dataframe\n",
    "df_fx[\"fx_czk_eur_annual_avg\"] = df_fx.iloc[:, 1:].mean(axis=1)\n",
    "\n",
    "#drop the original columns\n",
    "df_fx.drop(df_fx.columns[1:5], axis=1, inplace=True)\n",
    "\n",
    "# save to parquet\n",
    "# df_fx.to_parquet(output_file, engine=\"pyarrow\", compression=\"snappy\", index=False)\n",
    "# print(\"Annual FX rates data saved to:\", output_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import price indices w/o energy\n",
    "**Data Source:** CZSO\n",
    "- **Data Type:** Import price indices excluding energy\n",
    "- see src_01_data_curation/data_curation_import_prices.ipynb for details \n",
    "Data: \n",
    "```csv\n",
    "Year,Index\n",
    "2008,91.87\n",
    "2009,92.44\n",
    "2010,92.05\n",
    "2011,92.34\n",
    "2012,94.5\n",
    "2013,95.46\n",
    "2014,98.56\n",
    "2015,100.0\n",
    "2016,97.99\n",
    "2017,97.32\n",
    "2018,95.26\n",
    "2019,96.2\n",
    "2020,97.48\n",
    "2021,99.0\n",
    "2022,105.88\n",
    "2023,104.64\n",
    "2024,107.73\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file: data/source_cleaned/import_price_index_ex_energy.csv\n",
    "# read the import price index data\n",
    "script_dir = os.getcwd()  # Current directory in Jupyter\n",
    "project_root = os.path.abspath(os.path.join(script_dir, \"..\"))\n",
    "input_file = os.path.join(project_root, \"data\", \"source_cleaned\", \"import_price_index_ex_energy.csv\")\n",
    "\n",
    "# Read the import price index data\n",
    "df_import_price_index = pd.read_csv(input_file)\n",
    "\n",
    "\n",
    "\n",
    "# rename Year to year, to integer\n",
    "df_import_price_index.rename(columns={\"Year\": \"year\"}, inplace=True)\n",
    "df_import_price_index[\"year\"] = df_import_price_index[\"year\"].astype(int, errors=\"ignore\")\n",
    "# rename index column to value, to float\n",
    "df_import_price_index.rename(columns={\"Index\": \"value\"}, inplace=True)\n",
    "df_import_price_index[\"value\"] = df_import_price_index[\"value\"].astype(float, errors=\"ignore\")\n",
    "\n",
    "# add metric column with value \"import_price_index_ex_energy\"\n",
    "df_import_price_index[\"metric\"] = \"import_price_index_ex_energy\"\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "year",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "value",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "metric",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "18bc8a3c-fb4e-4845-9800-ff9ef53311b4",
       "rows": [
        [
         "0",
         "2008",
         "91.87",
         "import_price_index_ex_energy"
        ],
        [
         "1",
         "2009",
         "92.44",
         "import_price_index_ex_energy"
        ],
        [
         "2",
         "2010",
         "92.05",
         "import_price_index_ex_energy"
        ],
        [
         "3",
         "2011",
         "92.34",
         "import_price_index_ex_energy"
        ],
        [
         "4",
         "2012",
         "94.5",
         "import_price_index_ex_energy"
        ],
        [
         "5",
         "2013",
         "95.46",
         "import_price_index_ex_energy"
        ],
        [
         "6",
         "2014",
         "98.56",
         "import_price_index_ex_energy"
        ],
        [
         "7",
         "2015",
         "100.0",
         "import_price_index_ex_energy"
        ],
        [
         "8",
         "2016",
         "97.99",
         "import_price_index_ex_energy"
        ],
        [
         "9",
         "2017",
         "97.32",
         "import_price_index_ex_energy"
        ],
        [
         "10",
         "2018",
         "95.26",
         "import_price_index_ex_energy"
        ],
        [
         "11",
         "2019",
         "96.2",
         "import_price_index_ex_energy"
        ],
        [
         "12",
         "2020",
         "97.48",
         "import_price_index_ex_energy"
        ],
        [
         "13",
         "2021",
         "99.0",
         "import_price_index_ex_energy"
        ],
        [
         "14",
         "2022",
         "105.88",
         "import_price_index_ex_energy"
        ],
        [
         "15",
         "2023",
         "104.64",
         "import_price_index_ex_energy"
        ],
        [
         "16",
         "2024",
         "107.73",
         "import_price_index_ex_energy"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 17
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>value</th>\n",
       "      <th>metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008</td>\n",
       "      <td>91.87</td>\n",
       "      <td>import_price_index_ex_energy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009</td>\n",
       "      <td>92.44</td>\n",
       "      <td>import_price_index_ex_energy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010</td>\n",
       "      <td>92.05</td>\n",
       "      <td>import_price_index_ex_energy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011</td>\n",
       "      <td>92.34</td>\n",
       "      <td>import_price_index_ex_energy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012</td>\n",
       "      <td>94.50</td>\n",
       "      <td>import_price_index_ex_energy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2013</td>\n",
       "      <td>95.46</td>\n",
       "      <td>import_price_index_ex_energy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2014</td>\n",
       "      <td>98.56</td>\n",
       "      <td>import_price_index_ex_energy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2015</td>\n",
       "      <td>100.00</td>\n",
       "      <td>import_price_index_ex_energy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016</td>\n",
       "      <td>97.99</td>\n",
       "      <td>import_price_index_ex_energy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2017</td>\n",
       "      <td>97.32</td>\n",
       "      <td>import_price_index_ex_energy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2018</td>\n",
       "      <td>95.26</td>\n",
       "      <td>import_price_index_ex_energy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2019</td>\n",
       "      <td>96.20</td>\n",
       "      <td>import_price_index_ex_energy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2020</td>\n",
       "      <td>97.48</td>\n",
       "      <td>import_price_index_ex_energy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2021</td>\n",
       "      <td>99.00</td>\n",
       "      <td>import_price_index_ex_energy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2022</td>\n",
       "      <td>105.88</td>\n",
       "      <td>import_price_index_ex_energy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2023</td>\n",
       "      <td>104.64</td>\n",
       "      <td>import_price_index_ex_energy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2024</td>\n",
       "      <td>107.73</td>\n",
       "      <td>import_price_index_ex_energy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    year   value                        metric\n",
       "0   2008   91.87  import_price_index_ex_energy\n",
       "1   2009   92.44  import_price_index_ex_energy\n",
       "2   2010   92.05  import_price_index_ex_energy\n",
       "3   2011   92.34  import_price_index_ex_energy\n",
       "4   2012   94.50  import_price_index_ex_energy\n",
       "5   2013   95.46  import_price_index_ex_energy\n",
       "6   2014   98.56  import_price_index_ex_energy\n",
       "7   2015  100.00  import_price_index_ex_energy\n",
       "8   2016   97.99  import_price_index_ex_energy\n",
       "9   2017   97.32  import_price_index_ex_energy\n",
       "10  2018   95.26  import_price_index_ex_energy\n",
       "11  2019   96.20  import_price_index_ex_energy\n",
       "12  2020   97.48  import_price_index_ex_energy\n",
       "13  2021   99.00  import_price_index_ex_energy\n",
       "14  2022  105.88  import_price_index_ex_energy\n",
       "15  2023  104.64  import_price_index_ex_energy\n",
       "16  2024  107.73  import_price_index_ex_energy"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_import_price_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### merge data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annual economy data saved to: /Users/adam/Library/Mobile Documents/com~apple~CloudDocs/School/Master's Thesis/Analysis/profit-margins-inflation/data/source_cleaned/economy_annual_tidy.parquet\n"
     ]
    }
   ],
   "source": [
    "# merge data: final_annual, df_hicp_annual, df_wages, df_gdp, df_unemp, df_fx on \"year\"\n",
    "df_final = final_annual.merge(df_hicp_annual, on=\"year\", how=\"left\")\n",
    "df_final = df_final.merge(df_wages, on=\"year\", how=\"left\")\n",
    "df_final = df_final.merge(df_gdp, on=\"year\", how=\"left\")\n",
    "df_final = df_final.merge(df_unemp, on=\"year\", how=\"left\")\n",
    "df_final = df_final.merge(df_fx, on=\"year\", how=\"left\")\n",
    "\n",
    "\n",
    "# convert to tidy data\n",
    "df_final = pd.melt(df_final, id_vars=[\"year\"], var_name=\"metric\", value_name=\"value\")\n",
    "\n",
    "# append the import price index data\n",
    "df_import_price_index = df_import_price_index[[\"year\", \"metric\", \"value\"]]\n",
    "df_final = pd.concat([df_final, df_import_price_index], ignore_index=True)\n",
    "                                              \n",
    "\n",
    "# save to parquet\n",
    "output_file = os.path.join(output_folder, \"economy_annual_tidy.parquet\")\n",
    "df_final.to_parquet(output_file, engine=\"pyarrow\", compression=\"snappy\", index=False)\n",
    "print(\"Annual economy data saved to:\", output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
