{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Curation\n",
    "transforming the data into a format that is suitable for analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data from MagnusWeb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define script_dir for Jupyter Notebook\n",
    "script_dir = os.getcwd()  # Use current working directory instead of __file__\n",
    "project_root = os.path.abspath(os.path.join(script_dir, \"..\"))\n",
    "\n",
    "input_file = os.path.join(project_root, \"data\", \"source_raw\", \"magnusweb\", \"export-7.csv\")\n",
    "output_folder = os.path.join(project_root, \"data\", \"source_cleaned\")\n",
    "\n",
    "# Create output folder if it doesn't exist\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# Read the CSV file with semicolon delimiter and proper quoting\n",
    "df = pd.read_csv(input_file, delimiter=';', quotechar='\"')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------\n",
    "# 1. Identify static columns vs. melt columns\n",
    "# --------------------------------------\n",
    "# static (identifier) columns\n",
    "id_cols = [\n",
    "    \"IČO\",\n",
    "    \"Název subjektu\",\n",
    "    \"Hlavní NACE\",\n",
    "    \"Hlavní NACE - kód\",\n",
    "    \"Vedlejší NACE CZ\",\n",
    "    \"Vedlejší NACE CZ - kód\",\n",
    "    \"Hlavní OKEČ\",\n",
    "    \"Hlavní OKEČ - kód\",\n",
    "    \"Vedlejší OKEČ\",\n",
    "    \"Vedlejší OKEČ - kód\",\n",
    "    \"Institucionální sektory (ESA 2010)\",\n",
    "    \"Institucionální sektory (ESA 95)\",\n",
    "    \"Lokalita\",\n",
    "    \"Kraj\",\n",
    "    \"Počet zaměstnanců\",\n",
    "    \"Kategorie obratu\",\n",
    "    \"Audit\",\n",
    "    \"Konsolidace\",\n",
    "    \"Měna\",\n",
    "    \"Datum vzniku\",\n",
    "    \"Datum zrušení\",\n",
    "    # decide on those two:\n",
    "    \"Rok\",\n",
    "    \"Čtvrtletí\",\n",
    "]\n",
    "\n",
    "\n",
    "# We assume everything else is time-coded columns to be melted:\n",
    "time_cols = [c for c in df.columns if c not in id_cols]\n",
    "\n",
    "# --------------------------------------\n",
    "# 2. Melt the DataFrame\n",
    "# --------------------------------------\n",
    "melted = df.melt(\n",
    "    id_vars=id_cols,       # keep these columns as they are\n",
    "    value_vars=time_cols,  # the columns to unpivot\n",
    "    var_name=\"raw_variable\", \n",
    "    value_name=\"value\"\n",
    ")\n",
    "\n",
    "# --------------------------------------\n",
    "# 3. Define a function to parse raw_variable into (year, quarter, metric)\n",
    "# --------------------------------------\n",
    "def parse_colname(col):\n",
    "    \"\"\"\n",
    "    Parse column names like:\n",
    "      - '2023/4Q Aktiva celkem'\n",
    "      - '4Q/2001 Tržby Výkony'\n",
    "      - '2023 Kategorie obratu'\n",
    "      - 'Hospodářský výsledek před zdaněním' (no time)\n",
    "    Returns (year, quarter, metric).\n",
    "    \"\"\"\n",
    "    col = col.strip()\n",
    "    \n",
    "    # 1) Check patterns like 'YYYY/Qx' or 'Qx/YYYY'\n",
    "    #    We'll look for a pattern of either '(\\d{4})/(\\dQ)' or '(\\dQ)/(\\d{4})'\n",
    "    #    We'll then see what's after that for the metric name.\n",
    "    \n",
    "    # Regex approach:\n",
    "    # Explanation:\n",
    "    #   ^(\\d{4})/(\\dQ)   => matches e.g. \"2023/4Q\"\n",
    "    #   or\n",
    "    #   ^(\\dQ)/(\\d{4})   => matches e.g. \"4Q/2023\"\n",
    "    # We also allow more flexible (like '(\\dQ)/(\\d{4})' => '4Q/2001')\n",
    "    # Then everything that follows is the metric name\n",
    "    pattern_1 = re.compile(r\"\"\"\n",
    "        ^\n",
    "        (?:\n",
    "          (?P<year1>\\d{4})           # group year\n",
    "          /(?P<qtr1>\\dQ)             # slash Q\n",
    "          \\s+(?P<metric1>.*)        # remainder\n",
    "        )\n",
    "        |\n",
    "        (?:\n",
    "          (?P<qtr2>\\dQ)\n",
    "          /(?P<year2>\\d{4})\n",
    "          \\s+(?P<metric2>.*)\n",
    "        )\n",
    "        $ \n",
    "    \"\"\", re.VERBOSE)\n",
    "    \n",
    "    match_1 = pattern_1.match(col)\n",
    "    if match_1:\n",
    "        # figure out if we matched the first or second branch\n",
    "        if match_1.group(\"year1\") is not None:\n",
    "            year = match_1.group(\"year1\")\n",
    "            quarter = match_1.group(\"qtr1\")\n",
    "            metric = match_1.group(\"metric1\")\n",
    "        else:\n",
    "            quarter = match_1.group(\"qtr2\")\n",
    "            year = match_1.group(\"year2\")\n",
    "            metric = match_1.group(\"metric2\")\n",
    "        return year, quarter, metric.strip()\n",
    "    \n",
    "    # 2) Check pattern like 'YYYY Kategorie obratu'\n",
    "    #    That is: 4 digits at start, a space, then the metric\n",
    "    pattern_2 = re.compile(r\"^(\\d{4})\\s+(.*)$\")\n",
    "    match_2 = pattern_2.match(col)\n",
    "    if match_2:\n",
    "        year = match_2.group(1)\n",
    "        metric = match_2.group(2).strip()\n",
    "        return year, None, metric\n",
    "\n",
    "    # 3) If none of the above patterns, assume no time dimension in col\n",
    "    return None, None, col  # (year=None, quarter=None, metric=col)\n",
    "\n",
    "# Apply the parser\n",
    "melted[[\"year\", \"quarter\", \"metric\"]] = melted[\"raw_variable\"].apply(\n",
    "    lambda x: pd.Series(parse_colname(x))\n",
    ")\n",
    "\n",
    "# Optionally, you might want to convert year to numeric and \n",
    "# quarter to just an integer (if '4Q' => 4).\n",
    "def quarter_to_int(q):\n",
    "    \"\"\"\n",
    "    Convert string like '1Q', '2Q', '3Q', '4Q' to integer 1..4\n",
    "    or None if missing/invalid.\n",
    "    \"\"\"\n",
    "    if isinstance(q, str) and q.endswith(\"Q\"):\n",
    "        return int(q.replace(\"Q\", \"\"))\n",
    "    return None if pd.isna(q) else q\n",
    "\n",
    "melted[\"quarter\"] = melted[\"quarter\"].apply(quarter_to_int)\n",
    "melted[\"year\"] = pd.to_numeric(melted[\"year\"], errors=\"coerce\")  # or keep as str\n",
    "\n",
    "# --------------------------------------\n",
    "# 4. Clean up columns\n",
    "# --------------------------------------\n",
    "# We can drop \"raw_variable\" if we like:\n",
    "melted.drop(columns=[\"raw_variable\"], inplace=True)\n",
    "\n",
    "# Reorder columns for clarity\n",
    "# (Below is just an example order)\n",
    "final_cols = [\n",
    "    # Firm-level / static columns\n",
    "    \"IČO\",\n",
    "    \"Název subjektu\",\n",
    "    \"Hlavní NACE\",\n",
    "    \"Hlavní NACE - kód\",\n",
    "    \"Vedlejší NACE CZ\",\n",
    "    \"Vedlejší NACE CZ - kód\",\n",
    "    \"Hlavní OKEČ\",\n",
    "    \"Hlavní OKEČ - kód\",\n",
    "    \"Vedlejší OKEČ\",\n",
    "    \"Vedlejší OKEČ - kód\",\n",
    "    \"Institucionální sektory (ESA 2010)\",\n",
    "    \"Institucionální sektory (ESA 95)\",\n",
    "    \"Lokalita\",\n",
    "    \"Kraj\",\n",
    "    \"Počet zaměstnanců\",\n",
    "    \"Kategorie obratu\",\n",
    "    \"Audit\",\n",
    "    \"Konsolidace\",\n",
    "    \"Měna\",\n",
    "    \"Datum vzniku\",\n",
    "    \"Datum zrušení\",\n",
    "    # Newly parsed time and metric columns from the melt\n",
    "    \"year\",\n",
    "    \"quarter\",\n",
    "    \"metric\",\n",
    "    \"value\",\n",
    "]\n",
    "melted = melted[final_cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns using a mapping dictionary for clarity\n",
    "rename_mapping = {\n",
    "    \"IČO\": \"ico\",\n",
    "    \"Název subjektu\": \"name\",\n",
    "    \"Hlavní NACE\": \"main_nace\",\n",
    "    \"Hlavní NACE - kód\": \"main_nace_code\",\n",
    "    \"Vedlejší NACE CZ\": \"sub_nace_cz\",\n",
    "    \"Vedlejší NACE CZ - kód\": \"sub_nace_cz_code\",\n",
    "    \"Hlavní OKEČ\": \"main_okec\",\n",
    "    \"Hlavní OKEČ - kód\": \"main_okec_code\",\n",
    "    \"Vedlejší OKEČ\": \"sub_okec\",\n",
    "    \"Vedlejší OKEČ - kód\": \"sub_okec_code\",\n",
    "    \"Institucionální sektory (ESA 2010)\": \"esa2010\",\n",
    "    \"Institucionální sektory (ESA 95)\": \"esa95\",\n",
    "    \"Lokalita\": \"locality\",\n",
    "    \"Kraj\": \"region\",\n",
    "    \"Počet zaměstnanců\": \"num_employees\",\n",
    "    \"Kategorie obratu\": \"turnover_cat\",\n",
    "    \"Audit\": \"audit\",\n",
    "    \"Konsolidace\": \"consolidation\",\n",
    "    \"Měna\": \"currency\",\n",
    "    \"Datum vzniku\": \"date_founded\",\n",
    "    \"Datum zrušení\": \"date_dissolved\",\n",
    "    \"year\": \"year\",\n",
    "    \"quarter\": \"quarter\",\n",
    "    \"metric\": \"metric\",\n",
    "    \"value\": \"value\"\n",
    "}\n",
    "\n",
    "# Apply the renaming\n",
    "melted.rename(columns=rename_mapping, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "measure_mapping = {\n",
    "    \"Hospodářský výsledek před zdaněním\": \"profit_pre_tax\",\n",
    "    \"Hospodářský výsledek za účetní období\": \"profit_net\",\n",
    "    \"Provozní hospodářský výsledek\": \"oper_profit\",\n",
    "    \"Náklady\": \"costs\",\n",
    "    \"Obrat, Výnosy\": \"sales_revenue\",\n",
    "    \"Obrat Výnosy\": \"sales_revenue\",\n",
    "    \"Tržby, Výkony\": \"turnover\",\n",
    "    \"Tržby Výkony\": \"turnover\",\n",
    "    \"Aktiva celkem\": \"total_assets\",\n",
    "    \"Stálá aktiva\": \"fixed_assets\",\n",
    "    \"Oběžná aktiva\": \"current_assets\",\n",
    "    \"Ostatní aktiva\": \"other_assets\",\n",
    "    \"Pasiva celkem\": \"total_liabilities\",\n",
    "    \"Vlastní kapitál\": \"equity\",\n",
    "    \"Cizí zdroje\": \"debt\",\n",
    "    \"Ostatní pasiva\": \"other_liabilities\"\n",
    "}\n",
    "\n",
    "# Map the metric names to the new names\n",
    "melted[\"metric\"] = melted[\"metric\"].replace(measure_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Cleaning \n",
    "\n",
    "# 1. Convert audit, consolidation to categorical\n",
    "melted[\"audit\"] = melted[\"audit\"].astype(\"category\")\n",
    "melted[\"consolidation\"] = melted[\"consolidation\"].astype(\"category\")\n",
    "\n",
    "# 2. Convert currency from Czech strings to \"CZK\"/\"EUR\" and store as category\n",
    "currency_map = {\n",
    "    \"Česká koruna\": \"CZK\",\n",
    "    \"Euro\": \"EUR\"\n",
    "}\n",
    "melted[\"currency\"] = melted[\"currency\"].replace(currency_map)\n",
    "melted[\"currency\"] = melted[\"currency\"].astype(\"category\")\n",
    "\n",
    "# 3. Keep date_dissolved, parse as datetime (although it may be all NaN)\n",
    "melted[\"date_dissolved\"] = pd.to_datetime(melted[\"date_dissolved\"], errors=\"coerce\")\n",
    "\n",
    "# 4. Convert date_founded from string to datetime\n",
    "melted[\"date_founded\"] = pd.to_datetime(melted[\"date_founded\"], errors=\"coerce\")\n",
    "\n",
    "# 5. Convert esa2010, esa95, locality, region, etc. to categories\n",
    "melted[\"esa2010\"] = melted[\"esa2010\"].astype(\"category\")\n",
    "melted[\"esa95\"] = melted[\"esa95\"].astype(\"category\")\n",
    "melted[\"locality\"] = melted[\"locality\"].astype(\"category\")\n",
    "melted[\"region\"] = melted[\"region\"].astype(\"category\")\n",
    "\n",
    "# 6. Convert ICO (firm ID) to string (instead of numeric)\n",
    "melted[\"ico\"] = melted[\"ico\"].astype(str)\n",
    "\n",
    "# 7. Convert main_nace, main_nace_code, sub_nace_cz, sub_nace_cz_code, etc. to categories\n",
    "melted[\"main_nace\"] = melted[\"main_nace\"].astype(\"category\")\n",
    "melted[\"main_nace_code\"] = melted[\"main_nace_code\"].astype(\"category\")\n",
    "melted[\"sub_nace_cz\"] = melted[\"sub_nace_cz\"].astype(\"category\")\n",
    "melted[\"sub_nace_cz_code\"] = melted[\"sub_nace_cz_code\"].astype(\"category\")\n",
    "\n",
    "# 8. Convert main_okec, main_okec_code, sub_okec, sub_okec_code to category\n",
    "melted[\"main_okec\"] = melted[\"main_okec\"].astype(\"category\")\n",
    "melted[\"main_okec_code\"] = melted[\"main_okec_code\"].astype(\"category\")\n",
    "melted[\"sub_okec\"] = melted[\"sub_okec\"].astype(\"category\")\n",
    "melted[\"sub_okec_code\"] = melted[\"sub_okec_code\"].astype(\"category\")\n",
    "\n",
    "# 9. Convert turnover_cat to category\n",
    "melted[\"turnover_cat\"] = melted[\"turnover_cat\"].astype(\"category\")\n",
    "\n",
    "# 10. Convert metric to category (assuming you already applied measure name mapping)\n",
    "melted[\"metric\"] = melted[\"metric\"].astype(\"category\")\n",
    "\n",
    "# 11. Convert num_employees to integer (pandas nullable Int64 if missing)\n",
    "melted[\"num_employees\"] = melted[\"num_employees\"].astype(\"Int64\")\n",
    "\n",
    "# 12. Convert quarter to integer (nullable Int64 if it has NaNs)\n",
    "melted[\"quarter\"] = melted[\"quarter\"].astype(\"Int64\")\n",
    "\n",
    "# 13. Convert year to integer (nullable Int64 if it has NaNs)\n",
    "melted[\"year\"] = melted[\"year\"].astype(\"Int64\")\n",
    "\n",
    "# 14. 'value' remains float64 (the numeric measure), no change needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mapping dictionaries for audit and consolidation\n",
    "audit_map = {\"Ano\": \"Yes\", \"Ne\": \"No\"}\n",
    "consolidation_map = {\"Ano\": \"Yes\", \"Ne\": \"No\"}\n",
    "\n",
    "# Apply the mappings. Missing values (NaN) will remain unchanged.\n",
    "melted[\"audit\"] = melted[\"audit\"].replace(audit_map)\n",
    "melted[\"consolidation\"] = melted[\"consolidation\"].replace(consolidation_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert datetime columns to only the date (Python date objects)\n",
    "melted[\"date_founded\"] = melted[\"date_founded\"].dt.date\n",
    "melted[\"date_dissolved\"] = melted[\"date_dissolved\"].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary of the data: column name, data type, number of unique values, first 5 value \n",
    "summary = melted.dtypes.to_frame(name='data_type')\n",
    "summary[\"num_unique\"] = melted.nunique()\n",
    "summary[\"first_5_values\"] = melted.apply(lambda x: x.unique()[:5].tolist())\n",
    "summary = summary.reset_index()\n",
    "summary.columns = [\"column_name\", \"data_type\", \"num_unique\", \"first_5_values\"]\n",
    "summary = summary.sort_values(by=\"column_name\")\n",
    "\n",
    "# print summary\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------\n",
    "# Save to parquet file\n",
    "output_file = os.path.join(output_folder, \"magnusweb_tidy.parquet\")\n",
    "melted.to_parquet(output_file, engine=\"pyarrow\", compression=\"snappy\")\n",
    "\n",
    "print(\"Tidy data saved to:\", output_file)\n",
    "#print(melted.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list NACE and NACE codes: \n",
    "nace_codes = melted[[\"main_nace\", \"main_nace_code\"]].drop_duplicates()\n",
    "nace_codes = nace_codes.sort_values(by=\"main_nace_code\")\n",
    "nace_codes.reset_index(drop=True, inplace=True)\n",
    "nace_codes.columns = [\"NACE\", \"NACE_code\"]\n",
    "nace_codes[0:30]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nace codes: number or characters table\n",
    "nace_codes[\"NACE_code\"].str.len().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# codes with less than 6 characters\n",
    "nace_codes[nace_codes[\"NACE_code\"].str.len() < 6].sort_values(by=\"NACE_code\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nace_codes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
