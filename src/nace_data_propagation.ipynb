{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a71a86d",
   "metadata": {},
   "source": [
    "# NACE Data Propagation Notebook\n",
    "\n",
    "## Introduction\n",
    "Maintains a dataset of economic indicators classified by NACE codes (wages, employees, PPI). Fills missing data at lower levels using higher-level aggregates or umbrella codes (e.g., B+C+D+E), ensuring comprehensive coverage.\n",
    "\n",
    "## Input Data\n",
    "• t_nace_matching.parquet – NACE hierarchy (levels 0–5).  \n",
    "• data_by_nace_annual_tidy.parquet – Economic indicators by NACE.\n",
    "\n",
    "## Propagation Logic\n",
    "1. Build a full hierarchy-year-metric grid.  \n",
    "2. Identify missing data in the combined table.  \n",
    "3. Search upwards from the missing NACE level to find available values.  \n",
    "4. Use special umbrella codes if direct parents lack data.  \n",
    "5. Record propagation source in the “source” column.\n",
    "6. For each missing entry, the algorithm searches at the next higher NACE level for available data \n",
    "   and continues recursively until it either finds a value or reaches the top-level. \n",
    "   If direct parents lack data, umbrella codes (e.g., B+C+D+E) serve as a fallback source.\n",
    "\n",
    "## Output\n",
    "Generates data_by_nace_annual_tidy_propagated.parquet with original plus newly propagated data.\n",
    "\n",
    "## Steps\n",
    "1. Setup, load data.  \n",
    "2. Filter for important metrics.  \n",
    "3. Expand umbrella codes (B+C+D+E, etc.).  \n",
    "4. Propagate missing values.  \n",
    "5. Save final dataset and produce basic summaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee555bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd903cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths\n",
    "script_dir = os.getcwd()  # Current directory in Jupyter\n",
    "project_root = os.path.abspath(os.path.join(script_dir, \"..\"))\n",
    "\n",
    "# Load NACE matching table\n",
    "nace_matching_file = os.path.join(project_root, \"data\", \"source_cleaned\", \"t_nace_matching.parquet\")\n",
    "df_nace_matching = pd.read_parquet(nace_matching_file)\n",
    "\n",
    "# Load the main NACE data file\n",
    "data_file = os.path.join(project_root, \"data\", \"source_cleaned\", \"data_by_nace_annual_tidy.parquet\")\n",
    "df_nace_data = pd.read_parquet(data_file)\n",
    "\n",
    "print(f\"NACE matching table shape: {df_nace_matching.shape}\")\n",
    "print(f\"NACE data shape: {df_nace_data.shape}\")\n",
    "print(f\"\\nNACE matching columns: {df_nace_matching.columns.tolist()}\")\n",
    "print(f\"NACE data columns: {df_nace_data.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184f29d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data for the metrics we want to propagate\n",
    "metrics_to_propagate = ['avg_wages_by_nace', 'no_of_employees_by_nace', 'ppi_by_nace']\n",
    "\n",
    "df_propagation_source = df_nace_data[df_nace_data['metric'].isin(metrics_to_propagate)].copy()\n",
    "\n",
    "print(f\"Data for propagation shape: {df_propagation_source.shape}\")\n",
    "print(f\"\\nMetrics distribution:\")\n",
    "print(df_propagation_source['metric'].value_counts())\n",
    "print(f\"\\nLevel distribution:\")\n",
    "print(df_propagation_source['level'].value_counts().sort_index())\n",
    "print(f\"\\nYear range: {df_propagation_source['year'].min()} - {df_propagation_source['year'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5814e2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# expand the rows that level=0 czso_code contains + to be listed separately for each NACE code in the source data df_propagation_source\n",
    "# e.g. expanding B+C+D+E to separate rows for B, C, D, E containing the same values (except for the NACE code)\n",
    "# since the names are already clean, the level0 is always in format czso_nace separated by \"+\"\n",
    "\n",
    "# Expand level-0 umbrella codes (czso_code containing \"+\") into separate rows\n",
    "umbrella_mask = (df_propagation_source['level'] == 0) & df_propagation_source['czso_code'].str.contains(r'\\+')\n",
    "umbrella_rows = df_propagation_source[umbrella_mask]\n",
    "\n",
    "# Split the combined code into components and explode\n",
    "expanded = (\n",
    "    umbrella_rows\n",
    "    .assign(czso_code=umbrella_rows['czso_code'].str.split(r'\\+'))\n",
    "    .explode('czso_code')\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Merge the expanded rows back into the original DataFrame\n",
    "df_propagation_source = pd.concat([\n",
    "    df_propagation_source[~umbrella_mask],  # Keep non-umbrella rows\n",
    "    expanded  # Add the expanded rows\n",
    "], ignore_index=True)\n",
    "# Ensure czso_code is stripped of whitespace\n",
    "df_propagation_source['czso_code'] = df_propagation_source['czso_code'].str.strip()\n",
    "\n",
    "# level is integer\n",
    "df_propagation_source['level'] = df_propagation_source['level'].astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cdbbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows with missing value in 'value' column\n",
    "df_propagation_source = df_propagation_source.dropna(subset=['value'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4546cf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def propagate_nace_data(df_source, df_nace_hierarchy, metrics_list):\n",
    "    \"\"\"\n",
    "    Propagate data from higher NACE levels to lower levels where data is missing.\n",
    "    Uses the hierarchical structure from level1_code, level2_code, etc.\n",
    "    \n",
    "    Parameters:\n",
    "    - df_source: DataFrame with NACE data to propagate. \n",
    "                 Expected columns: czso_code, level, name_cs, name_en, year, metric, value, unit, source.\n",
    "    - df_nace_hierarchy: DataFrame with NACE hierarchy information.\n",
    "                         Expected columns: czso_code, level, name_czso_cs, name_czso_en, levelX_code.\n",
    "    - metrics_list: List of metrics to propagate\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame with propagated data\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a copy of source data\n",
    "    df_result = df_source.copy()\n",
    "    \n",
    "    # Get all possible combinations of czso_code, year, and metric from hierarchy\n",
    "    years = df_source['year'].unique()\n",
    "    \n",
    "    # Create full hierarchy with all years and metrics\n",
    "    hierarchy_expanded = []\n",
    "    for metric in metrics_list:\n",
    "        for year in years:\n",
    "            temp_df = df_nace_hierarchy.copy()\n",
    "            temp_df['year'] = year\n",
    "            temp_df['metric'] = metric\n",
    "            hierarchy_expanded.append(temp_df)\n",
    "    \n",
    "    df_full_hierarchy = pd.concat(hierarchy_expanded, ignore_index=True)\n",
    "    \n",
    "    # Merge with existing data to identify missing combinations\n",
    "    # df_source columns: czso_code, level, name_cs, name_en, year, metric, value, unit, source\n",
    "    # df_full_hierarchy columns: czso_code, level, name_czso_cs, name_czso_en, year, metric, levelX_code\n",
    "    # Overlapping 'level' column will be suffixed.\n",
    "    # 'name_cs'/'name_en' vs 'name_czso_cs'/'name_czso_en' are distinct.\n",
    "    # 'unit', 'value', 'source' are only in df_source.\n",
    "    df_merged = pd.merge(\n",
    "        df_full_hierarchy,\n",
    "        df_source,\n",
    "        on=['czso_code', 'year', 'metric'],\n",
    "        how='left',\n",
    "        suffixes=('_hierarchy', '_data') # level -> level_hierarchy, level_data\n",
    "    )\n",
    "    \n",
    "    # Identify missing data (where value is NaN)\n",
    "    missing_mask = df_merged['value'].isna()\n",
    "    print(f\"Found {missing_mask.sum()} missing data points to potentially propagate\")\n",
    "    \n",
    "    # Sort by level (higher levels first for propagation) - use the hierarchy level\n",
    "    df_merged = df_merged.sort_values(['metric', 'year', 'level_hierarchy', 'czso_code'])\n",
    "    \n",
    "    # Propagation logic: for each missing data point, try to find parent data\n",
    "    propagated_records = []\n",
    "    \n",
    "    for metric in metrics_list:\n",
    "        print(f\"\\nProcessing metric: {metric}\")\n",
    "        metric_data = df_merged[df_merged['metric'] == metric].copy()\n",
    "        \n",
    "        for year_val in years: # Renamed to avoid conflict with 'year' column name\n",
    "            year_data = metric_data[metric_data['year'] == year_val].copy()\n",
    "            \n",
    "            # Get existing data for this year/metric\n",
    "            # This data comes from df_merged, so it has 'level_data' (original NACE level from df_source)\n",
    "            # and 'unit' (original unit from df_source)\n",
    "            existing_data_for_year_metric = year_data[~year_data['value'].isna()].copy()\n",
    "            \n",
    "            # Prepare a map of available data. If a czso_code exists at multiple NACE levels\n",
    "            # (e.g. 'C' at level 1 and 'C' at level 0 from expansion), prioritize higher NACE level.\n",
    "            # 'level_data' is the NACE level from the original df_source.\n",
    "            existing_data_prepared = existing_data_for_year_metric.sort_values(\n",
    "                'level_data', ascending=False\n",
    "            ).drop_duplicates(subset=['czso_code'], keep='first')\n",
    "            \n",
    "            existing_data_map = {}\n",
    "            for _, r_existing in existing_data_prepared.iterrows():\n",
    "                existing_data_map[r_existing['czso_code']] = {\n",
    "                    'value': r_existing['value'],\n",
    "                    'level': r_existing['level_data'], # Actual NACE level of this source data point\n",
    "                    'unit': r_existing['unit']         # Unit of this source data point\n",
    "                }\n",
    "            \n",
    "            # Try to propagate to missing data points for this year/metric\n",
    "            missing_data_for_year_metric = year_data[year_data['value'].isna()]\n",
    "            \n",
    "            for _, row in missing_data_for_year_metric.iterrows():\n",
    "                target_code = row['czso_code']\n",
    "                # target_level is the NACE level of the item we are trying to fill (from hierarchy)\n",
    "                target_level = row['level_hierarchy'] \n",
    "                \n",
    "                propagated_value = None\n",
    "                source_code_found = None\n",
    "                actual_level_of_source_code = None # NACE level of the source_code_found\n",
    "                propagated_unit = 'unknown'      # Default unit\n",
    "\n",
    "                # Try to find parent data by going up the hierarchy\n",
    "                # Loop from parent (target_level-1) up to NACE Level 1 ancestor\n",
    "                for i in range(target_level - 1, 0, -1): \n",
    "                    parent_code_at_level_i = None\n",
    "                    if i == 1: parent_code_at_level_i = row['level1_code']\n",
    "                    elif i == 2: parent_code_at_level_i = row['level2_code']\n",
    "                    elif i == 3: parent_code_at_level_i = row['level3_code']\n",
    "                    elif i == 4: parent_code_at_level_i = row['level4_code']\n",
    "                    elif i == 5: parent_code_at_level_i = row['level5_code']\n",
    "                    \n",
    "                    if pd.notna(parent_code_at_level_i) and parent_code_at_level_i in existing_data_map:\n",
    "                        parent_data_entry = existing_data_map[parent_code_at_level_i]\n",
    "                        propagated_value = parent_data_entry['value']\n",
    "                        actual_level_of_source_code = parent_data_entry['level']\n",
    "                        actual_level_of_source_code = int(actual_level_of_source_code) \n",
    "                        propagated_unit = parent_data_entry['unit']\n",
    "                        source_code_found = parent_code_at_level_i \n",
    "\n",
    "                        break # Found data from the closest parent in hierarchy\n",
    "                \n",
    "                if propagated_value is not None:\n",
    "                    new_record = {\n",
    "                        'czso_code': target_code,\n",
    "                        'level': target_level, # NACE level of the item being filled\n",
    "                        'name_cs': row['name_czso_cs'], # Name from hierarchy table\n",
    "                        'name_en': row['name_czso_en'], # Name from hierarchy table\n",
    "                        'year': year_val,\n",
    "                        'metric': metric,\n",
    "                        'value': propagated_value,\n",
    "                        'unit': propagated_unit if pd.notna(propagated_unit) else 'unknown',\n",
    "                        'source': f\"PROPAGATED from level {actual_level_of_source_code} ({source_code_found})\"\n",
    "                    }\n",
    "                    propagated_records.append(new_record)\n",
    "    \n",
    "    print(f\"\\nGenerated {len(propagated_records)} propagated records\")\n",
    "    \n",
    "    if propagated_records:\n",
    "        df_propagated_new = pd.DataFrame(propagated_records)\n",
    "        df_result = pd.concat([df_result, df_propagated_new], ignore_index=True)\n",
    "\n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc40f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the propagation\n",
    "print(\"Starting data propagation...\")\n",
    "print(f\"Original data shape: {df_propagation_source.shape}\")\n",
    "\n",
    "df_propagated = propagate_nace_data(\n",
    "    df_propagation_source, \n",
    "    df_nace_matching, \n",
    "    metrics_to_propagate\n",
    ")\n",
    "\n",
    "print(f\"\\nPropagated data shape: {df_propagated.shape}\")\n",
    "print(f\"Added {df_propagated.shape[0] - df_propagation_source.shape[0]} new records\")\n",
    "\n",
    "# Check the results\n",
    "print(\"\\n=== Propagation Results ===\")\n",
    "print(\"Source distribution:\")\n",
    "print(df_propagated['source'].value_counts())\n",
    "\n",
    "print(\"\\nMetric distribution after propagation:\")\n",
    "for metric in metrics_to_propagate:\n",
    "    metric_data = df_propagated[df_propagated['metric'] == metric]\n",
    "    print(f\"{metric}: {len(metric_data)} records\")\n",
    "    print(f\"  - Original: {len(metric_data[~metric_data['source'].str.contains('PROPAGATED', na=False)])}\")\n",
    "    print(f\"  - Propagated: {len(metric_data[metric_data['source'].str.contains('PROPAGATED', na=False)])}\")\n",
    "\n",
    "df_final = df_propagated.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03504807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with czso_code that are not in the hierarchy\n",
    "df_final = df_final[df_final['czso_code'].isin(df_nace_matching['czso_code'])]\n",
    "\n",
    "# add magnus_nace column based on the matching table\n",
    "df_final = df_final.merge(\n",
    "    df_nace_matching[['czso_code', 'magnus_nace']],\n",
    "    on='czso_code',\n",
    "    how='left'\n",
    ")\n",
    "# 2nd column\n",
    "df_final = df_final[['czso_code', 'magnus_nace', 'level', 'name_cs', 'name_en', 'year', 'metric', 'value', 'unit', 'source']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e527c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the propagated data\n",
    "output_folder = os.path.join(project_root, \"data\", \"source_cleaned\")\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "output_file = os.path.join(output_folder, \"data_by_nace_annual_tidy_propagated.parquet\")\n",
    "\n",
    "df_final.to_parquet(output_file, index=False, engine=\"pyarrow\")\n",
    "print(f\"\\nPropagated data saved to: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f577bc9",
   "metadata": {},
   "source": [
    "## Data Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299a016e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate summary statistics\n",
    "print(\"\\n=== Final Summary ===\")\n",
    "print(f\"Total records: {len(df_final):,}\")\n",
    "print(f\"Date range: {df_final['year'].min()} - {df_final['year'].max()}\")\n",
    "print(f\"Unique NACE codes: {df_final['czso_code'].nunique()}\")\n",
    "print(f\"Levels represented: {sorted(df_final['level'].unique())}\")\n",
    "\n",
    "print(\"\\nRecords by metric:\")\n",
    "for metric in sorted(df_final['metric'].unique()):\n",
    "    count = len(df_final[df_final['metric'] == metric])\n",
    "    propagated_count = len(df_final[\n",
    "        (df_final['metric'] == metric) & \n",
    "        (df_final['source'].str.contains('PROPAGATED', na=False))\n",
    "    ])\n",
    "    print(f\"  {metric}: {count:,} total ({propagated_count:,} propagated)\")\n",
    "\n",
    "print(\"\\nRecords by level:\")\n",
    "for level in sorted(df_final['level'].unique()):\n",
    "    count = len(df_final[df_final['level'] == level])\n",
    "    print(f\"  Level {level}: {count:,} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562c92d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_data_availability(df_data, df_nace_hierarchy, target_metric):\n",
    "    \"\"\"\n",
    "    Summarizes data availability for a given metric across all years.\n",
    "\n",
    "    For each year, it shows how many NACE codes have data, how many are missing,\n",
    "    and details for the missing NACE codes including their parent NACE codes.\n",
    "\n",
    "    Parameters:\n",
    "    - df_data: DataFrame containing the data (e.g., df_final).\n",
    "               Expected columns: 'czso_code', 'year', 'metric', 'value', 'level', \n",
    "                                 'name_cs', 'name_en'.\n",
    "    - df_nace_hierarchy: DataFrame with NACE hierarchy information (e.g., df_nace_matching).\n",
    "                         Expected columns: 'czso_code', 'level', 'name_czso_cs', \n",
    "                                           'name_czso_en', 'level1_code', 'level2_code', \n",
    "                                           'level3_code', 'level4_code', 'level5_code'.\n",
    "    - target_metric: String, the name of the metric to summarize.\n",
    "    \"\"\"\n",
    "    print(f\"--- Data Availability Summary for Metric: {target_metric} ---\")\n",
    "\n",
    "    metric_data = df_data[df_data['metric'] == target_metric]\n",
    "    \n",
    "    if metric_data.empty:\n",
    "        print(f\"No data found for metric: {target_metric}\")\n",
    "        return\n",
    "\n",
    "    unique_years = sorted(metric_data['year'].unique())\n",
    "\n",
    "    # Select relevant columns from NACE hierarchy for the full grid\n",
    "    hierarchy_cols = ['czso_code', 'level', 'name_czso_cs', 'name_czso_en', \n",
    "                      'level1_code', 'level2_code', 'level3_code', \n",
    "                      'level4_code', 'level5_code']\n",
    "    df_nace_base = df_nace_hierarchy[hierarchy_cols].copy()\n",
    "    df_nace_base.rename(columns={'level': 'nace_level_hierarchy', # To avoid potential merge conflicts\n",
    "                                 'name_czso_cs': 'name_cs_hierarchy',\n",
    "                                 'name_czso_en': 'name_en_hierarchy'}, inplace=True)\n",
    "\n",
    "\n",
    "    for year in unique_years:\n",
    "        print(f\"\\n--- Year: {year} ---\")\n",
    "        \n",
    "        # Create a full grid of all NACE codes for this year and metric\n",
    "        df_year_full_nace = df_nace_base.copy()\n",
    "        df_year_full_nace['year'] = year\n",
    "        df_year_full_nace['metric'] = target_metric\n",
    "        \n",
    "        # Data for the current year and metric\n",
    "        current_year_metric_data = metric_data[metric_data['year'] == year]\n",
    "        \n",
    "        # Merge the full NACE grid with the actual data\n",
    "        # We are interested in 'value' from current_year_metric_data\n",
    "        merged_df = pd.merge(\n",
    "            df_year_full_nace,\n",
    "            current_year_metric_data[['czso_code', 'year', 'metric', 'value', 'source']],\n",
    "            on=['czso_code', 'year', 'metric'],\n",
    "            how='left'\n",
    "        )\n",
    "        \n",
    "        available_mask = merged_df['value'].notna()\n",
    "        missing_mask = merged_df['value'].isna()\n",
    "        \n",
    "        available_count = available_mask.sum()\n",
    "        missing_count = missing_mask.sum()\n",
    "        \n",
    "        print(f\"  NACE codes with data: {available_count}\")\n",
    "        print(f\"  NACE codes missing data: {missing_count}\")\n",
    "        \n",
    "        if missing_count > 0:\n",
    "            print(f\"  Details for missing NACE codes (showing first 5 if many):\")\n",
    "            missing_details_df = merged_df[missing_mask]\n",
    "            \n",
    "            for _, row in missing_details_df.head(5).iterrows():\n",
    "                parent_info = []\n",
    "                if pd.notna(row['level5_code']): parent_info.append(f\"L5P:{row['level5_code']}\")\n",
    "                if pd.notna(row['level4_code']): parent_info.append(f\"L4P:{row['level4_code']}\")\n",
    "                if pd.notna(row['level3_code']): parent_info.append(f\"L3P:{row['level3_code']}\")\n",
    "                if pd.notna(row['level2_code']): parent_info.append(f\"L2P:{row['level2_code']}\")\n",
    "                if pd.notna(row['level1_code']): parent_info.append(f\"L1P:{row['level1_code']}\")\n",
    "                \n",
    "                print(f\"    - Code: {row['czso_code']} (Level: {row['nace_level_hierarchy']}), \"\n",
    "                      f\"Name: {row['name_en_hierarchy'][:30]}..., \" # Truncate name\n",
    "                      f\"Parents: [{', '.join(parent_info)}]\")\n",
    "            if missing_count > 5:\n",
    "                print(f\"    ... and {missing_count - 5} more missing NACE codes.\")\n",
    "    print(\"\\n--- End of Summary ---\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23d2ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_data_availability(df_final, df_nace_matching, 'ppi_by_nace')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
