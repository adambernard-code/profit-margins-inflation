{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data by NACE curation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### PPI by NACE (industrial)\n",
    "\n",
    "source: CZSO\n",
    "\n",
    "- yearly, base 2015\n",
    "- contains industry (B,C,D,E), and levels 1, 2, 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths\n",
    "script_dir = os.getcwd()  # Current directory in Jupyter\n",
    "project_root = os.path.abspath(os.path.join(script_dir, \"..\"))\n",
    "input_file = os.path.join(project_root, \"data\", \"source_raw\", \"NACE\", \"ipccr031725_21_CSU_PPI_by_NACE_industry.xlsx\")\n",
    "\n",
    "# Read the Excel file\n",
    "df_ppi_by_nace_ind = pd.read_excel(input_file, sheet_name=\"IR15 roční (yearly)\", header=1)\n",
    "\n",
    "# delete last two rows (notes)\n",
    "df_ppi_by_nace_ind = df_ppi_by_nace_ind.iloc[:-2]\n",
    "\n",
    "# transform code column: \n",
    "# replace \"B,C,D,E\" -> \"industry\"\n",
    "#df_ppi_by_nace_ind[\"Code\"] = df_ppi_by_nace_ind[\"Code\"].replace({\"B,C,D,E\": \"industry\"})\n",
    "\n",
    "# Unnamed: 2 to name_cs, Unnamed: 3 to name_en\n",
    "df_ppi_by_nace_ind.rename(columns={\"Unnamed: 2\": \"name_cs\", \"Unnamed: 3\": \"name_en\"}, inplace=True)\n",
    "\n",
    "# deduct 1 from Level\n",
    "df_ppi_by_nace_ind[\"Level\"] = df_ppi_by_nace_ind[\"Level\"] - 1\n",
    "# rename to level\n",
    "df_ppi_by_nace_ind.rename(columns={\"Level\": \"level\"}, inplace=True)\n",
    "\n",
    "# rename Code to czso_code: consistency with other datasets\n",
    "df_ppi_by_nace_ind.rename(columns={\"Code\": \"czso_code\"}, inplace=True)\n",
    "\n",
    "# transform to tidy format\n",
    "df_ppi_by_nace_ind = df_ppi_by_nace_ind.melt(id_vars=[\"czso_code\", \"name_cs\", \"name_en\", \"level\"], var_name=\"year\", value_name=\"value\")\n",
    "\n",
    "# drop pre 2000 values\n",
    "df_ppi_by_nace_ind = df_ppi_by_nace_ind[df_ppi_by_nace_ind[\"year\"].astype(int) >= 2000]\n",
    "\n",
    "# add metric: ppi_by_nace\n",
    "df_ppi_by_nace_ind[\"metric\"] = \"ppi_by_nace_industry\"\n",
    "# add unit: index\n",
    "df_ppi_by_nace_ind[\"unit\"] = \"2015=100\"\n",
    "\n",
    "# replace i.d. and : by null in value col (: = missing value, i.d. = individual data)\n",
    "df_ppi_by_nace_ind[\"value\"] = df_ppi_by_nace_ind[\"value\"].replace({\"i.d.\" : None, \":\": None})\n",
    "\n",
    "# data type conversion\n",
    "df_ppi_by_nace_ind[\"value\"] = df_ppi_by_nace_ind[\"value\"].astype(float)\n",
    "df_ppi_by_nace_ind[\"year\"] = df_ppi_by_nace_ind[\"year\"].astype(int)\n",
    "df_ppi_by_nace_ind[\"czso_code\"] = df_ppi_by_nace_ind[\"czso_code\"].astype(str)\n",
    "df_ppi_by_nace_ind[\"level\"] = df_ppi_by_nace_ind[\"level\"].astype(int)\n",
    "df_ppi_by_nace_ind[\"name_cs\"] = df_ppi_by_nace_ind[\"name_cs\"].astype(str)\n",
    "df_ppi_by_nace_ind[\"name_en\"] = df_ppi_by_nace_ind[\"name_en\"].astype(str)\n",
    "df_ppi_by_nace_ind[\"metric\"] = df_ppi_by_nace_ind[\"metric\"].astype(str)\n",
    "df_ppi_by_nace_ind[\"unit\"] = df_ppi_by_nace_ind[\"unit\"].astype(str)\n",
    "\n",
    "# source\n",
    "df_ppi_by_nace_ind[\"source\"] = \"CZSO - industry\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SPPI by NACE aggregated\n",
    "\n",
    "source: CZSO https://csu.gov.cz/produkty/ipc_ts > Table 1.1\n",
    "\n",
    "- yearly, base: \n",
    "   - 2020 for agriculture\n",
    "   - 2015 for other industries\n",
    "- contains SPPI (aggregated) for NACE sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = os.path.join(project_root, \"data\", \"source_raw\", \"NACE\", \"ipccr052025_11_CSU_PPI_an_SPPI_by_NACE_aggregated.xlsx\")\n",
    "\n",
    "# Read the Excel file\n",
    "df_ppi_by_nace_agg = pd.read_excel(input_file, sheet_name=\"List1\", header=1)\n",
    "\n",
    "# drop first 4 rows and anything after row 44, since we are interested only in yearly data\n",
    "df_ppi_by_nace_agg = df_ppi_by_nace_agg.iloc[5:42]\n",
    "\n",
    "# NACE matching table for SPPI data, in the correct order\n",
    "\n",
    "df_nace_sppi_cols = pd.DataFrame([\n",
    "    # name, level, czso_code\n",
    "    [\"Agricultural producer incl. fish\", 0, \"A\"],\n",
    "    [\"Agricultural producer - Animals\", 1, \"014+015+017+031\"],\n",
    "    [\"Agricultural producer - Crops\", 1, \"011+012+013\"],\n",
    "    [\"Industrial producer\", 0, \"B+C+D+E\"],\n",
    "    [\"Construction work\", 0, \"F\"],\n",
    "    [\"Market services price\", 0, \"G+H+I+J+K+L+M+N\"],\n",
    "    [\"Market services price excl. advertising services\", 0, \"G+H+I+J+K+L+M+N-731\"],\n",
    "    [\"Land transport services and transport services via pipelines\", 1, \"49\"],\n",
    "    [\"Water transport services\", 1, \"50\"],\n",
    "    [\"Warehousing and support services for transportation\", 1, \"52\"],\n",
    "    [\"Postal and courier services\", 1, \"53\"],\n",
    "    [\"Publishing services\", 1, \"58\"],\n",
    "    [\"Motion picture, video and television programme production, sound recording and music publishing\", 1, \"59\"],\n",
    "    [\"Programming and broadcasting services\", 1, \"60\"],\n",
    "    [\"Telecommunications services\", 1, \"61\"],\n",
    "    [\"Computer programming, consultancy\", 1, \"62\"],\n",
    "    [\"Information services\", 1, \"63\"],\n",
    "    [\"Insurance\", 1, \"65\"],\n",
    "    [\"Real estate services\", 1, \"68\"],\n",
    "    [\"Legal and accounting services\", 1, \"69\"],\n",
    "    [\"Services of head offices; management consulting services\", 1, \"70\"],\n",
    "    [\"Architectural and engineering services\", 1, \"71\"],\n",
    "    [\"Advertising and market research services\", 1, \"73\"],\n",
    "    [\"Other professional, scientific, technic. services\", 1, \"74\"],\n",
    "    [\"Rental and leasing services\", 1, \"77\"],\n",
    "    [\"Employment services\", 1, \"78\"],\n",
    "    [\"Security and investigation services\", 1, \"80\"],\n",
    "    [\"Services to buildings and landscape\", 1, \"81\"],\n",
    "    [\"Office administrative and other support services\", 1, \"82\"],\n",
    "], columns=[\"name_source_row\", \"level\", \"czso_code\"])\n",
    "\n",
    "# enrich with name_cs, name_en from t_nace_matching.parquet\n",
    "nace_matching_file = os.path.join(project_root, \"data\", \"source_cleaned\", \"t_nace_matching.parquet\")\n",
    "df_nace_matching = pd.read_parquet(nace_matching_file)\n",
    "\n",
    "# merge with NACE matching table\n",
    "df_nace_sppi_cols = pd.merge(\n",
    "    df_nace_sppi_cols,\n",
    "    df_nace_matching[[\"czso_code\", \"name_czso_cs\", \"name_czso_en\"]],\n",
    "    on=\"czso_code\",\n",
    "    how=\"left\",\n",
    "    suffixes=(\"\", \"_y\")\n",
    ")\n",
    "# fill in missing name_czso_cs and name_czso_en with name_source_row\n",
    "df_nace_sppi_cols[\"name_czso_cs\"] = df_nace_sppi_cols[\"name_czso_cs\"].fillna(df_nace_sppi_cols[\"name_source_row\"])\n",
    "df_nace_sppi_cols[\"name_czso_en\"] = df_nace_sppi_cols[\"name_czso_en\"].fillna(df_nace_sppi_cols[\"name_source_row\"])\n",
    "\n",
    "# add rows for czso_code, name_czso_cs, and name_czso_en to df_ppi_by_nace_agg on top\n",
    "czso_code_row = [\"year\"] + df_nace_sppi_cols['czso_code'].tolist()\n",
    "df_czso_code_row = pd.DataFrame([czso_code_row], columns=df_ppi_by_nace_agg.columns)\n",
    "\n",
    "df_ppi_by_nace_agg = pd.concat([df_czso_code_row, df_ppi_by_nace_agg], ignore_index=True)\n",
    "# drop original identifier rows\n",
    "df_ppi_by_nace_agg.drop(index=[1, 2], inplace=True)\n",
    "\n",
    "# first row as header\n",
    "df_ppi_by_nace_agg.columns = df_ppi_by_nace_agg.iloc[0]\n",
    "df_ppi_by_nace_agg = df_ppi_by_nace_agg[1:]\n",
    "\n",
    "# transform to tidy format\n",
    "df_ppi_by_nace_agg = df_ppi_by_nace_agg.melt(id_vars=[\"year\"], var_name=\"czso_code\", value_name=\"value\")\n",
    "\n",
    "# enrich with name_cs, name_en, level from df_nace_sppi_cols\n",
    "df_ppi_by_nace_agg = pd.merge(\n",
    "    df_ppi_by_nace_agg,\n",
    "    df_nace_sppi_cols[[\"czso_code\", \"name_czso_cs\", \"name_czso_en\", \"level\"]],\n",
    "    on=\"czso_code\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# rename columns\n",
    "df_ppi_by_nace_agg.rename(columns={\n",
    "    \"name_czso_cs\": \"name_cs\",\n",
    "    \"name_czso_en\": \"name_en\"\n",
    "}, inplace=True)\n",
    "\n",
    "# add metric: ppi_by_nace\n",
    "df_ppi_by_nace_agg[\"metric\"] = \"ppi_by_nace_aggregated\"\n",
    "\n",
    "# add source\n",
    "df_ppi_by_nace_agg[\"source\"] = \"CZSO - without industry\"\n",
    "\n",
    "# Data type conversion for year and value before rebasing\n",
    "df_ppi_by_nace_agg[\"year\"] = pd.to_numeric(df_ppi_by_nace_agg[\"year\"], errors='coerce')\n",
    "df_ppi_by_nace_agg.dropna(subset=[\"year\"], inplace=True) # Drop rows where year could not be converted\n",
    "df_ppi_by_nace_agg[\"year\"] = df_ppi_by_nace_agg[\"year\"].astype(int)\n",
    "df_ppi_by_nace_agg[\"value\"] = pd.to_numeric(df_ppi_by_nace_agg[\"value\"], errors='coerce')\n",
    "\n",
    "# Rebase specific NACE codes from base year 2020 to 2015 \n",
    "agri_codes_to_rebase = [\"A\", \"014+015+017+031\", \"011+012+013\"]\n",
    "\n",
    "for code in agri_codes_to_rebase:\n",
    "    current_code_mask = df_ppi_by_nace_agg['czso_code'] == code\n",
    "    \n",
    "    # Find the value in 2015 for this code (which is currently base 2020=100)\n",
    "    value_2015_base2020_series = df_ppi_by_nace_agg.loc[current_code_mask & (df_ppi_by_nace_agg['year'] == 2015), 'value']\n",
    "    \n",
    "    if not value_2015_base2020_series.empty and pd.notna(value_2015_base2020_series.iloc[0]) and value_2015_base2020_series.iloc[0] != 0:\n",
    "        base_value_for_rebase = value_2015_base2020_series.iloc[0]\n",
    "        # Rebase: (current_value / value_at_new_base_in_old_series) * 100\n",
    "        df_ppi_by_nace_agg.loc[current_code_mask, 'value'] = \\\n",
    "            (df_ppi_by_nace_agg.loc[current_code_mask, 'value'] / base_value_for_rebase) * 100\n",
    "    else:\n",
    "        # Handle cases where 2015 value is missing or zero if necessary, e.g., by setting values to NaN or logging a warning\n",
    "        print(f\"Warning: Could not rebase NACE code {code} due to missing or zero 2015 value.\")\n",
    "        df_ppi_by_nace_agg.loc[current_code_mask, 'value'] = pd.NA # Or keep as is, depending on desired behavior\n",
    "\n",
    "# round to one decimal places\n",
    "df_ppi_by_nace_agg[\"value\"] = df_ppi_by_nace_agg[\"value\"].round(1)\n",
    "\n",
    "# Set unit for all to 2015=100 as all are now (or originally were) on this base\n",
    "df_ppi_by_nace_agg[\"unit\"] = \"2015=100\"\n",
    "\n",
    "# Final data type conversions\n",
    "df_ppi_by_nace_agg[\"czso_code\"] = df_ppi_by_nace_agg[\"czso_code\"].astype(str)\n",
    "df_ppi_by_nace_agg[\"name_cs\"] = df_ppi_by_nace_agg[\"name_cs\"].astype(str)\n",
    "df_ppi_by_nace_agg[\"name_en\"] = df_ppi_by_nace_agg[\"name_en\"].astype(str)\n",
    "df_ppi_by_nace_agg[\"level\"] = df_ppi_by_nace_agg[\"level\"].astype(int)\n",
    "# year and value already converted, ensure correct type\n",
    "df_ppi_by_nace_agg[\"year\"] = df_ppi_by_nace_agg[\"year\"].astype(int)\n",
    "df_ppi_by_nace_agg[\"value\"] = df_ppi_by_nace_agg[\"value\"].astype(float) \n",
    "df_ppi_by_nace_agg[\"metric\"] = df_ppi_by_nace_agg[\"metric\"].astype(str)\n",
    "df_ppi_by_nace_agg[\"unit\"] = df_ppi_by_nace_agg[\"unit\"].astype(str)\n",
    "df_ppi_by_nace_agg[\"source\"] = df_ppi_by_nace_agg[\"source\"].astype(str)\n",
    "\n",
    "# Reorder columns to be consistent with other dataframes\n",
    "col_order = ['czso_code', 'level', 'name_cs', 'name_en', 'year', 'metric', 'value', 'unit', 'source']\n",
    "df_ppi_by_nace_agg = df_ppi_by_nace_agg[col_order]\n",
    "\n",
    "# remove pre 2000 values\n",
    "df_ppi_by_nace_agg = df_ppi_by_nace_agg[df_ppi_by_nace_agg[\"year\"] >= 2000]\n",
    "\n",
    "# remove industry [\"Industrial producer\", 0, \"B+C+D+E\"]\n",
    "df_ppi_by_nace_agg = df_ppi_by_nace_agg[df_ppi_by_nace_agg[\"czso_code\"] != \"B+C+D+E\"]\n",
    "# remove \"G+H+I+J+K+L+M+N-731\" - this data adds unnecessary complexity compared to market services data \n",
    "df_ppi_by_nace_agg = df_ppi_by_nace_agg[df_ppi_by_nace_agg[\"czso_code\"] != \"G+H+I+J+K+L+M+N-731\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merged PPI industry and PPI aggregated\n",
    "source: CZSO\n",
    "- yearly, base 2015\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Overlap Check: df_ppi_by_nace_ind vs df_ppi_by_nace_agg ---\n",
      "No overlap found between df_ppi_by_nace_ind and df_ppi_by_nace_agg based on 'czso_code' and 'year'.\n"
     ]
    }
   ],
   "source": [
    "# check whether there is any overlap between df_ppi_by_nace_ind and df_ppi_by_nace_agg\n",
    "\n",
    "print(\"--- Overlap Check: df_ppi_by_nace_ind vs df_ppi_by_nace_agg ---\")\n",
    "\n",
    "# Perform an inner merge on 'czso_code' and 'year'\n",
    "# Suffixes are added to distinguish columns from the two dataframes if they have other same-named columns\n",
    "overlap_df = pd.merge(\n",
    "    df_ppi_by_nace_ind[['czso_code', 'year', 'value', 'metric']],\n",
    "    df_ppi_by_nace_agg[['czso_code', 'year', 'value', 'metric']],\n",
    "    on=['czso_code', 'year'],\n",
    "    suffixes=('_ind', '_agg')\n",
    ")\n",
    "\n",
    "if not overlap_df.empty:\n",
    "    print(f\"Found {len(overlap_df)} overlapping records between industrial PPI and aggregated PPI.\")\n",
    "    print(\"Overlapping records (first 5):\")\n",
    "    print(overlap_df.head())\n",
    "    \n",
    "    print(\"\\nUnique overlapping czso_codes:\")\n",
    "    print(overlap_df['czso_code'].unique())\n",
    "else:\n",
    "    print(\"No overlap found between df_ppi_by_nace_ind and df_ppi_by_nace_agg based on 'czso_code' and 'year'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created df_ppi_unified by combining df_ppi_by_nace_ind and df_ppi_by_nace_agg.\n",
      "Shape of df_ppi_unified: (3350, 9)\n",
      "Unique metrics in df_ppi_unified: ['ppi_by_nace']\n",
      "Number of rows from industry PPI: 2675\n",
      "Number of rows from aggregated PPI: 675\n",
      "Total rows in unified PPI: 3350\n"
     ]
    }
   ],
   "source": [
    "# create the unified dataframe for PPI by NACE\n",
    "df_ppi_ind_for_combine = df_ppi_by_nace_ind.copy()\n",
    "df_ppi_agg_for_combine = df_ppi_by_nace_agg.copy()\n",
    "\n",
    "# Standardize the metric name to 'ppi_by_nace' for both dataframes\n",
    "df_ppi_ind_for_combine['metric'] = \"ppi_by_nace\"\n",
    "df_ppi_agg_for_combine['metric'] = \"ppi_by_nace\"\n",
    "\n",
    "# Concatenate the two PPI dataframes\n",
    "df_ppi_unified = pd.concat([df_ppi_ind_for_combine, df_ppi_agg_for_combine], ignore_index=True)\n",
    "\n",
    "print(f\"Created df_ppi_unified by combining df_ppi_by_nace_ind and df_ppi_by_nace_agg.\")\n",
    "print(f\"Shape of df_ppi_unified: {df_ppi_unified.shape}\")\n",
    "print(f\"Unique metrics in df_ppi_unified: {df_ppi_unified['metric'].unique()}\")\n",
    "print(f\"Number of rows from industry PPI: {len(df_ppi_ind_for_combine)}\")\n",
    "print(f\"Number of rows from aggregated PPI: {len(df_ppi_agg_for_combine)}\")\n",
    "print(f\"Total rows in unified PPI: {len(df_ppi_unified)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wages by NACE\n",
    "\n",
    "source: CZSO\n",
    "unit: Average gross monthly wage by activity of CZ-NACE\n",
    "CZK, per full-time equivalent employee\n",
    "\n",
    "- 2023 and 2024 preliminary data \n",
    "\n",
    "- we use \"Q1 - Q4\" data for the annual number \n",
    "\n",
    "-  The data refer only to the employees with an employment contract with the reporting units. Excludes persons performing public office, such as Members of Parliament, Senators, full-time councillors at all levels, judges, etc. The average wages refer to wages accounted for payment in the given period. \n",
    "\n",
    "- industry assigned level 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths\n",
    "input_file = os.path.join(project_root, \"data\", \"source_raw\", \"NACE\", \"pmzcr030625_2_wages by NACE.xlsx\")\n",
    "\n",
    "# Read the Excel file\n",
    "df_wages = pd.read_excel(input_file, sheet_name=\"List1\", header=4)\n",
    "\n",
    "# remove first two rows \n",
    "df_wages = df_wages.iloc[2:]\n",
    "\n",
    "# remove last three rows (notes)\n",
    "df_wages = df_wages.iloc[:-3]\n",
    "\n",
    "# rename columns: \n",
    "df_wages.rename(columns={\"Unnamed: 0\": \"czso_code\", \"Unnamed: 1\": \"name\"}, inplace=True)\n",
    "\n",
    "# keep only columns czso_code, name_cs and those that start with \"Q1-Q4\"\n",
    "df_wages = df_wages[[\"czso_code\", \"name\"] + [col for col in df_wages.columns if col.startswith(\"Q1-Q4\")]]\n",
    "# rename the columns from Q1-Q4\tQ1-Q4.1\tQ1-Q4.2\tQ1-Q4.3\tQ1-Q4.4 to 2000, 2001, 2002, 2003, 2004, ...\n",
    "df_wages.columns = [\"czso_code\", \"name\"] + [str(year) for year in range(2000, 2025)]\n",
    "\n",
    "# in czso_code replace  value that STARTS with \"B+C+D+E\" only with \"industry\"\n",
    "df_wages.loc[df_wages['czso_code'].str.startswith(\"B+C+D+E\", na=False), 'czso_code'] = \"industry\"\n",
    "# for industry fill in name\n",
    "df_wages.loc[df_wages['czso_code'] == \"industry\", 'name'] = \"Průmysl\\nIndustry\"\n",
    "\n",
    "# separate name into name_cs and name_en (separated by \\n)\n",
    "df_wages[['name_cs', 'name_en']] = df_wages['name'].str.split('\\n', expand=True)\n",
    "# remove name column\n",
    "df_wages.drop(columns=[\"name\"], inplace=True)\n",
    "\n",
    "# add level column: one letter: 1, industry = 0\n",
    "df_wages[\"level\"] = df_wages[\"czso_code\"].apply(lambda x: 0 if x == \"industry\" else 1)\n",
    "\n",
    "# transform to tidy format\n",
    "df_wages = df_wages.melt(id_vars=[\"czso_code\", \"name_cs\", \"name_en\", \"level\"], var_name=\"year\", value_name=\"value\")\n",
    "\n",
    "# unit avg_gross_monthly_per_fulltime\n",
    "df_wages[\"unit\"] = \"CZK_avg_gross_monthly_per_fulltime\"\n",
    "# metric wages_by_nace\n",
    "df_wages[\"metric\"] = \"avg_wages_by_nace\"\n",
    "\n",
    "# data type conversion\n",
    "df_wages[\"value\"] = df_wages[\"value\"].astype(float)\n",
    "df_wages[\"year\"] = df_wages[\"year\"].astype(int)\n",
    "df_wages[\"czso_code\"] = df_wages[\"czso_code\"].astype(str)\n",
    "df_wages[\"level\"] = df_wages[\"level\"].astype(int)\n",
    "df_wages[\"name_cs\"] = df_wages[\"name_cs\"].astype(str)\n",
    "df_wages[\"name_en\"] = df_wages[\"name_en\"].astype(str)\n",
    "df_wages[\"metric\"] = df_wages[\"metric\"].astype(str)\n",
    "df_wages[\"unit\"] = df_wages[\"unit\"].astype(str)\n",
    "\n",
    "# source\n",
    "df_wages[\"source\"] = \"CZSO\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### avg number of employees by NACE\n",
    "\n",
    "source: CZSO\n",
    "- thousands of employees or full-time equivalents\n",
    "- 2023 and 2024 preliminary data\n",
    "\n",
    "- manipulation similar to wages \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths\n",
    "input_file = os.path.join(project_root, \"data\", \"source_raw\", \"NACE\", \"pmzcr030625_3_csu avg number of employees by nace.xlsx\")\n",
    "\n",
    "# Read the Excel file\n",
    "df_employees = pd.read_excel(input_file, sheet_name=\"List1\", header=4)\n",
    "\n",
    "# remove first two rows \n",
    "df_employees = df_employees.iloc[2:]\n",
    "\n",
    "# remove last three rows (notes)\n",
    "df_employees = df_employees.iloc[:-3]\n",
    "\n",
    "# rename columns: \n",
    "df_employees.rename(columns={\"Unnamed: 0\": \"czso_code\", \"Unnamed: 1\": \"name\"}, inplace=True)\n",
    "\n",
    "# keep only columns czso_code, name_cs and those that start with \"Q1-Q4\"\n",
    "df_employees = df_employees[[\"czso_code\", \"name\"] + [col for col in df_employees.columns if col.startswith(\"Q1-Q4\")]]\n",
    "# rename the columns from Q1-Q4\tQ1-Q4.1\tQ1-Q4.2\tQ1-Q4.3\tQ1-Q4.4 to 2000, 2001, 2002, 2003, 2004, ...\n",
    "df_employees.columns = [\"czso_code\", \"name\"] + [str(year) for year in range(2000, 2025)]\n",
    "\n",
    "# in czso_code replace  value that STARTS with \"B+C+D+E\" only with \"industry\"\n",
    "df_employees.loc[df_employees['czso_code'].str.startswith(\"B+C+D+E\", na=False), 'czso_code'] = \"industry\"\n",
    "# for industry fill in name\n",
    "df_employees.loc[df_employees['czso_code'] == \"industry\", 'name'] = \"Průmysl\\nIndustry\"\n",
    "\n",
    "# separate name into name_cs and name_en (separated by \\n)\n",
    "df_employees[['name_cs', 'name_en']] = df_employees['name'].str.split('\\n', expand=True)\n",
    "# remove name column\n",
    "df_employees.drop(columns=[\"name\"], inplace=True)\n",
    "\n",
    "# add level column: one letter: 1, industry = 0\n",
    "df_employees[\"level\"] = df_employees[\"czso_code\"].apply(lambda x: 0 if x == \"industry\" else 1)\n",
    "\n",
    "# transform to tidy format\n",
    "df_employees = df_employees.melt(id_vars=[\"czso_code\", \"name_cs\", \"name_en\", \"level\"], var_name=\"year\", value_name=\"value\")\n",
    "\n",
    "# unit\n",
    "df_employees[\"unit\"] = \"ths\"\n",
    "# metric\n",
    "df_employees[\"metric\"] = \"no_of_employees_by_nace\"\n",
    "\n",
    "\n",
    "# data type conversion\n",
    "df_employees[\"value\"] = df_employees[\"value\"].astype(float)\n",
    "df_employees[\"year\"] = df_employees[\"year\"].astype(int)\n",
    "df_employees[\"czso_code\"] = df_employees[\"czso_code\"].astype(str)\n",
    "df_employees[\"level\"] = df_employees[\"level\"].astype(int)\n",
    "df_employees[\"name_cs\"] = df_employees[\"name_cs\"].astype(str)\n",
    "df_employees[\"name_en\"] = df_employees[\"name_en\"].astype(str)\n",
    "df_employees[\"metric\"] = df_employees[\"metric\"].astype(str)\n",
    "df_employees[\"unit\"] = df_employees[\"unit\"].astype(str)\n",
    "\n",
    "# source\n",
    "df_employees[\"source\"] = \"CZSO\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine and save to parquet\n",
    "df_combined = pd.concat([df_ppi_by_nace_ind, df_wages, df_employees, df_ppi_by_nace_agg, df_ppi_unified], ignore_index=True)\n",
    "# change order\n",
    "df_combined = df_combined[[\"czso_code\", \"level\", \"name_cs\", \"name_en\", \"year\", \"metric\", \"value\", \"unit\", \"source\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to /Users/adam/Library/Mobile Documents/com~apple~CloudDocs/School/Master's Thesis/Analysis/profit-margins-inflation/data/source_cleaned/data_by_nace_annual_tidy.parquet\n"
     ]
    }
   ],
   "source": [
    "# save to parquet\n",
    "output_folder = os.path.join(project_root, \"data\", \"source_cleaned\")\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "output_file = os.path.join(output_folder, \"data_by_nace_annual_tidy.parquet\")\n",
    "\n",
    "df_combined.to_parquet(output_file, index=False, engine=\"pyarrow\")\n",
    "print(f\"Data saved to {output_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
